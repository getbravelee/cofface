# 2주차

## 25.04.21



## 아이디어 회의...

### 1. 신규



#### 1. 커피 블렌딩 추천 & 소량 주문 서비스

참고:

- [Specialty-Coffee-Clustering-for-Beginners](https://github.com/Kyyle2114/Specialty-Coffee-Clustering-for-Beginners)

- [시그니처 블렌딩 커피 레시피 개발을 위한 생성형 AI 기술 활용 연구](https://www.kci.go.kr/kciportal/ci/sereArticleSearch/ciSereArtiView.kci?sereArticleSearchBean.artiId=ART003017865)

##### 1. 서비스 개요

- **서비스명**: BlendMe
- **목표**: 사용자 취향 기반 시그니처 블렌딩 커피 추천 → 추천된 블렌딩으로 소량 주문 가능 → 근처 제휴 카페에서 제공
- **형태**: 모바일 PWA(Web App)
- **주요 기능**:
  1. 간단한 설문 기반 취향 분석
  2. 생성형 AI 기반 블렌딩 커피 레시피 추천
  3. 블렌딩 비율 시뮬레이션 및 커스터마이징
  4. 소량 주문 (100g~250g) 및 근처 제휴 카페로 당일 배송
  5. 커피 추출 요청 (제휴 카페에서 즉석 추출, 픽업/배달)

------

##### 2. 기술 스택

- **프론트엔드**: React + Vite + TypeScript, TailwindCSS, PWA
- **백엔드**: Spring Boot, Fast API
- **AI 추천 엔진**: Fine-tuned OpenAI API (blending 레시피 생성용)
- **DB**: MySQL
- **인프라**: AWS EC2, S3

------

##### 3. 개발 계획



| 주차  | 주요 목표                            | 세부 내용                                                    |
| ----- | ------------------------------------ | ------------------------------------------------------------ |
| 1주차 | **데이터 정제 및 추천 로직 설계**    | - 데이터 분석 - 블렌딩 기준 구성 (산미, 바디, 로스팅, 지역 등) - 설문 → 성향 분류 매핑 구조 설계 - 추천 레시피 생성을 위한 Fine-tuning 데이터셋 구성 |
| 2주차 | **AI 추천 API 구축 및 테스트**       | - Fine-tuning 모델 학습 (OpenAI API) - ChatGPT 추천 API 서버 개발 - 간단한 테스트 UI 구성 후 시나리오 검증 |
| 3주차 | **웹앱 UI 개발 (모바일 중심)**       | - 사용자 설문/입력 UI - 결과 기반 추천 페이지 - 커스터마이징 및 주문 페이지 - PWA 지원 (오프라인 캐시 등) |
| 4주차 | **소량 주문 및 카페 연동 기능 구현** | - 주문 처리 API - 카페 매칭 및 추출 요청 - 주문 내역 및 알림 기능 - MVP 배포 및 피드백 수렴 |

------

##### 4. 핵심 기능 상세

###### AI 커피 레시피 추천

- 입력: `설문 결과 or 키워드 (ex. 고소하고 묵직한)`
- 출력: `원두 구성(브라질 40%, 에티오피아 30%, 과테말라 30%) + 로스팅 정도`
- 기술: Fine-tuned GPT 모델이 블렌딩 조합 추천

###### 블렌딩 주문 & 추출 요청

- 블렌딩 원두를 소량 포장 후 근처 제휴 카페로 배송
- 사용자는 해당 카페에서 픽업하거나, 추출 요청하여 음료 형태로 수령 가능
- 제휴 카페는 추출 비용 일부를 수수료로 확보 가능

------

##### 5. 기대 효과

- 커피 애호가에게 새로운 경험 제공 (AI x 개인화 x 실물 제공)
- 제휴 카페에는 추가 수익 및 유입 창출
- 데이터 기반 커피 시장 분석도 가능



#### 2. 공능제(공감능력제로)

**목표**:
사용자의 감정 인식 능력과 공감 능력을 시뮬레이션 기반 훈련을 통해 키우는 소셜 감정 교육 서비스
→ 감정 데이터 + 공감 상황 시뮬 + 피드백 루프

------

##### 핵심 기능 아이디어 정리

###### 1.  공감 시뮬레이션 게임

- **내용**: 여러 가지 상황(예: 친구가 화났을 때, 누군가 슬퍼 보일 때 등)을 **텍스트 기반 스토리텔링**이나 **2D 캐릭터 시뮬**로 보여주고,
- **유저 선택지**: “어떻게 반응할까?” → 선택지 고르기
- **피드백**: 선택한 공감 방식에 대해 AI가 피드백 제공 (“이런 반응은 상대가 위로받는 느낌을 줄 수 있어요!”)
- **데이터 활용**: 공감형 대화 데이터셋, 감정 태깅 자유대화



###### 2. MBTI 기반 공감 훈련법 추천

- MBTI 성격유형을 입력받고, 각 유형에 맞는 **훈련 루틴** 제안
- 예시:
  - INTP → 논리적 접근보단 감정을 드러내는 연습 훈련
  - ENFP → 공감은 넘치지만 경청 중심 훈련
- 간단한 MBTI 테스트도 포함 가능



###### 3. 음성 인식 기반 공감 타이밍 훈련

- 유저의 **음성 대화**를 받아서 감정이 담긴 발화인지 감지 (예: 짜증 섞인 말투, 우울한 느낌)
- "이럴 땐 뭐라고 반응할까?" → **공감 타이밍 추천** (예: “지금 바로 공감 표현하기!”)
- 음성인식으로 감정 인식 (오픈소스 음성 감정 모델 활용 가능)



###### 4. 일일 공감 미션

- “오늘 하루, 누군가를 위로할 수 있는 말을 해보세요!”
- 미션 수행 여부 기록 → 배지/레벨업 시스템으로 동기부여

------

###### 활용 가능한 AI/데이터 기술

| 분야           | 활용 방식                                  | 데이터                               |
| -------------- | ------------------------------------------ | ------------------------------------ |
| 감정 분석      | 텍스트 또는 음성으로 감정 태깅 감지        | 감정 자유대화 데이터 (성인/청소년용) |
| 공감 추천      | 상황 기반 반응 예측 모델 (RAG 가능)        | 공감형 대화 데이터, 대화 라벨        |
| 사용자 맞춤형  | MBTI 기반 퍼스널라이징                     | 오픈 MBTI 특징 텍스트                |
| 음성 인식 감정 | 음성에서 감정 추출 → 공감 반응 타이밍 유도 | 감정 라벨 음성 데이터                |

------

######  기술 스택

| 구성 요소      | 기술                                          |
| -------------- | --------------------------------------------- |
| 프론트엔드     | React + Tailwind + Zustand                    |
| 백엔드         | Python (FastAPI), SpringBoot                  |
| DB             | MySQL, MongoDB                                |
| 음성 감정 분석 | 오픈소스 모델 (e.g., SER, wav2vec2 fine-tune) |
| RAG 추천       | FAISS + OpenAI or LLM-lite 모델               |
| 배포           | Vercel / Render / EC2                         |

------

######  일정

| 주차  | 목표                                                    |
| ----- | ------------------------------------------------------- |
| 1주차 | 아이디어 구체화, 시나리오/데이터 분석, UI 설계          |
| 2주차 | 감정 분석 모델 탑재, 공감 시뮬 기본 구현                |
| 3주차 | MBTI 맞춤 훈련, 음성 감정 인식 연결, 피드백 시스템 개발 |
| 4주차 | 마무리, 버그 수정, 포트폴리오/발표 준비                 |

------

###### 부가기능 아이디어

- **공감 점수 시스템**: 유저가 응답할 때마다 "공감 지수" 상승

- **공감 일기장**: 감정 태깅 기반 자기 성찰 기능

-  **청소년용 & 성인용 모드 분리**: 시나리오 다르게 구성

  

### 2. 키위

#### 1. 공통

1. RAG - 추천, 빌드 가이드 등

   - GPT:

     ##### RAG 기반 추천 및 가이드 기능

     ###### 목표

     - 커스텀 키보드 입문자, 중급자를 위한 **용어 설명**, **가이드**, **부품 추천** 제공
     - 피드/검색 시 **연관 콘텐츠** 추천 (예: 유저가 검색한 키워드 기반 관련 조립 예시 피드 추천 등)

     ###### 구성

     - **데이터 소스 구축**:

       - 키보드 용어집 (CSV 또는 JSON 형태, 직접 정리 가능)
       - 자주 묻는 질문/조립 예시/조립자 팁 등 커뮤니티에서 수집하거나 직접 제작

     - **RAG 구성요소**:

       - `LangChain` or `LlamaIndex` 기반 RAG 셋업
       - OpenAI API 또는 Llama2/3 로컬 모델 (FastChat 등으로 가능)

     - **사용 흐름**:

       - 사용자가 검색하거나 “도와줘” 버튼 누르면 → 키보드 상황 설명 → 추천/설명 응답

     - **응답 예시**:

       > “사무실에서 쓸 거고 조용했으면 좋겠어요”
       > → “정숙성을 원하신다면 저소음 적축 또는 흑축 계열을 추천드려요. 키보드 하우징은 알루미늄보다는 아크릴/플라스틱이 덜 울립니다.”

     ##### 구현 팁

     - 키보드 용어/가이드 PDF나 문서 수집해서 텍스트 벡터화
     - 검색어 연동 or 채팅형 입력 가능 (선택)
       

   - 가이드 문서로 Pinecone에 벡터 DB 생성 후, Python Fast API로 RAG 구축 - Upstage, OpenAI API 사용



##### 2. 데스크톱 사이트

1. 피드 / 게시판에  올라온 제품의 소리를 자신의 컴퓨터에서 스피커/이어폰으로 어떤 소리인지 들어보기

   - 소리 합성 모델을 사용하여 해당 키보드의 소리를 추측하고 합성(만약 소리가 같이 올라와 있다면 거기서 추출, 없다면 태그된 제품들 중 소리에 영향을 미치는 부품으로 소리 합성) 후 사용자가 본인의 키보드를 치면 거기에 맞게 타건음이 출력됨

   - GPT:

     ###### 목표

     - 피드 게시물의 키보드 소리를 사용자가 직접 타이핑하며 **실시간 타건음**으로 들을 수 있게
     - 소리가 없으면, 태그된 부품을 바탕으로 **합성된 소리** 제공

     ###### 구성

     - **입력 기반 실시간 음성 출력**:
       - Web Audio API 활용 (브라우저에서 타이핑 소리 출력)
       - 키보드 이벤트 연동
     - **타건음 소스 처리**:
       - 업로드된 실제 음성 → Spectrogram 추출 or Sample 분할
       - 없을 경우: 부품(스위치/하우징/윤활 여부 등) 태그 기반 프리셋 조합 (WAV/mp3 미리 정의)
     - **소리 합성**:
       - 초간단 버전: 부품 조합별 미리 만들어둔 샘플 세트
       - 고급 버전: Diffusion 모델 or NeMo 등으로 파형 생성 가능

     ###### 구현 팁

     - 빠르게 MVP 만들려면 타건음 샘플만 잘 정리해도 충분
     - 컴퓨터 타이핑 → 해당 키 위치별 or 랜덤으로 타건음 재생하는 방식

2. 원하는 키보드의 형태를 (말로? - STT) 설명 또는 선택(UI)하면 해당하는 키보드 부품을 조합하여 견적 자동 작성, 소리 합성하여 출력

   - 각 상품에 분류 태그가 달려 있어야 할 듯

   - GPT:
   
     ###### 목표
   
     - 사용자가 말로 원하는 키보드 스타일 설명 → 시스템이 부품 구성 + 견적 + 타건음 생성
   
     ###### 구성
   
     - **STT (음성 → 텍스트)**:
       - `Whisper API` or `Naver CLOVA STT` or `Google STT`
     - **텍스트 파싱 → 의미 분석**:
       - 예: “몽글몽글한 느낌의 로우피치 텐키리스” → 속성 분해
         - 소리 느낌 → 키압/스위치
         - 외형 → 레이아웃/재질
         - 가격대까지 말하면 예산까지 추출 가능
     - **자동 조합**:
       - 키워드 매핑된 상품 목록 기반 자동 견적서 생성
       - 최종 구성: 스위치, 키캡, 하우징, 스태빌라이저, 윤활 여부
     - **타건음 생성은 앞에서 기획한 기능 재사용**
   
     ###### 예시 응답
   
     > "조용한 풀알루미늄 텐키리스 키보드 원해요"
     > →
     > “다음과 같은 구성은 어떠세요?”
   
     - 하우징: 풀알루미늄 (EX: Keychron Q3)
     - 스위치: 저소음 흑축 (예: Gateron Silent Ink)
     - 타건음: (합성된 소리 재생)
   
   